{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNjdSxtsE0nfIk5tFDQ4KaB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gillilandim/Gilliard/blob/main/Prova_modulo_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEtZoYZ_VDad"
      },
      "outputs": [],
      "source": [
        "### Prova modulo 15"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas e definição da função getDF()\n",
        "#Essa célula é responsável por carregar as bibliotecas necessárias e a função que gera o conjunto de dados."
      ],
      "metadata": {
        "id": "rvO5kya6WJiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time"
      ],
      "metadata": {
        "id": "l_IRGW1RWJ0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para criar o DataFrame de exemplo\n",
        "def getDF():\n",
        "    dic__ = {\"User_1\":[np.nan, np.nan, np.nan, 1, 7, 2, 3, 8],\n",
        "         \"User_2\":[9,10,2,2,6,5,3,8],\n",
        "         \"User_3\":[4, 7, 9, 6,6,10,10,2],\n",
        "         \"User_4\":[np.nan, 7, 9, 5, 5, 10, 9, 1],\n",
        "         \"User_5\":[7.0,6.0,3.0,8.0,3,4.0,3.0, 2],\n",
        "         \"User_6\":[np.nan, np.nan, 9, 9,6,8,9,np.nan],\n",
        "         \"User_7\":[3,5,4,4,3,3,9,np.nan],\n",
        "         \"User_8\":[10,10,10,10,2,2,2,2],\n",
        "         \"User_9\":[9,9,np.nan,8,3,3,1,np.nan],\n",
        "         \"User_10\":[9,8,10,9,3,4,2,1],\n",
        "         \"User_11\":[4,4,3,3,9,9,8,10],\n",
        "         \"User_12\":[2,2,4,1,8,10,10,9],\n",
        "         \"User_13\":[1,4,1,3,7,10,7,8],\n",
        "         \"User_14\":[3,3,2,1,1,10, np.nan,10],\n",
        "         \"User_15\":[9,9,8,10,4,2,np.nan,1]\n",
        "        }\n",
        "    df = pd.DataFrame(dic__).T\n",
        "    df.columns = ['Filme_'+str(int(i+1)) for i in range(8)]\n",
        "    return df"
      ],
      "metadata": {
        "id": "xM7tGPiWWJ3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o DataFrame\n",
        "df = getDF()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zoSkDqlXWJ55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title Filme_2\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "df['Filme_2'].plot(kind='hist', bins=20, title='Filme_2')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "5jlioL9BYwJf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wqrf-pQHWJ8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Divisão dos dados em treino, validação e teste\n",
        "# Aqui, os dados são divididos em três subconjuntos: treino, validação e teste."
      ],
      "metadata": {
        "id": "gs_YWGyrWJ-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para dividir o conjunto de dados\n",
        "def split_train_validation_test(df, qtd=2):\n",
        "    train_df = df.copy()\n",
        "    validation_df = pd.DataFrame(index=df.index, columns=df.columns)\n",
        "    test_df = pd.DataFrame(index=df.index, columns=df.columns)\n",
        "\n",
        "    for user in df.index:\n",
        "        user_ratings = df.loc[user]\n",
        "        rated_movies = user_ratings[user_ratings.notna()].index.tolist()\n",
        "\n",
        "        if len(rated_movies) >= qtd:\n",
        "            validation_movies = np.random.choice(rated_movies, size=1, replace=False)\n",
        "            remaining_rated_movies = [movie for movie in rated_movies if movie not in validation_movies]\n",
        "            test_movies = np.random.choice(remaining_rated_movies, size=1, replace=False)\n",
        "\n",
        "            for movie in validation_movies:\n",
        "                validation_df.loc[user, movie] = train_df.loc[user, movie]\n",
        "                train_df.loc[user, movie] = np.nan\n",
        "\n",
        "            for movie in test_movies:\n",
        "                test_df.loc[user, movie] = train_df.loc[user, movie]\n",
        "                train_df.loc[user, movie] = np.nan\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nFLNXCOMWKBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo os dados\n",
        "train_df, validation_df, test_df = split_train_validation_test(df, qtd=2)\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "36uIT4AXWKEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Definição da classe de Fatoração Matricial\n",
        "### Essa célula contém a implementação da fatoração matricial, que será usada para ajustar o modelo."
      ],
      "metadata": {
        "id": "VhVAExNdWKSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a classe de Fatoração Matricial\n",
        "class MatrixFactorization():\n",
        "\n",
        "    def __init__(self, dataframe, K, steps, alpha, beta):\n",
        "        self.df = dataframe\n",
        "        self.K = K\n",
        "        self.steps = steps\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def fit(self):\n",
        "        t0 = time.time()\n",
        "\n",
        "        R = self.df.values\n",
        "        N, M = R.shape\n",
        "\n",
        "        #inicio aleatorio\n",
        "        P = np.random.rand(N,self.K)\n",
        "        Q = np.random.rand(self.K,M)\n",
        "\n",
        "        lista_erro_step = []\n",
        "\n",
        "        #loop\n",
        "        for step in range(self.steps):\n",
        "\n",
        "            mse_total_step = 0\n",
        "            #varrendo todas as entradas da matriz R\n",
        "            for i in range(len(R)):\n",
        "                for j in range(len(R[i])):\n",
        "                    #validando se o valor associado está preenchido\n",
        "                    if not np.isnan(R[i][j]):\n",
        "\n",
        "                        #calculando o erro:\n",
        "                        eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
        "                        mse_total_step += (eij)**2\n",
        "                        #alterando os valores\n",
        "                        for k in range(self.K):\n",
        "                            P[i][k] = P[i][k] + self.alpha * ( 2 * eij * Q[k][j] - self.beta * P[i][k])\n",
        "                            Q[k][j] = Q[k][j] + self.alpha * ( 2 * eij * P[i][k] - self.beta * Q[k][j])\n",
        "\n",
        "            lista_erro_step.append(mse_total_step)\n",
        "\n",
        "        self.P = P\n",
        "        self.Q = Q\n",
        "        self.lista_erro_step = lista_erro_step\n",
        "        t1 = time.time()\n",
        "        #print(\"Fatoração concluída. Tempo aproximado:\", int((t1-t0)/60)+1, 'minuto(s).')\n",
        "\n",
        "    def predict(self):\n",
        "        return self.P.dot(self.Q)\n"
      ],
      "metadata": {
        "id": "a_BQxeNuWKWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcXEBRBxWKYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros a serem testados\n",
        "param_grid = {\n",
        "    'K': [2, 3, 4],\n",
        "    'steps': [1000, 2000],\n",
        "    'alpha': [0.001, 0.002],\n",
        "    'beta': [0.01, 0.02]\n",
        "}\n",
        "\n",
        "best_rmse = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for K in param_grid['K']:\n",
        "    for steps in param_grid['steps']:\n",
        "        for alpha in param_grid['alpha']:\n",
        "            for beta in param_grid['beta']:\n",
        "                fat = MatrixFactorization(dataframe=train_df, K=K, steps=steps, alpha=alpha, beta=beta)\n",
        "                fat.fit()\n",
        "                predictions = pd.DataFrame(fat.predict(), columns=df.columns, index=df.index)\n",
        "\n",
        "                rmse = 0\n",
        "                count = 0\n",
        "                for user in validation_df.index:\n",
        "                    for movie in validation_df.columns:\n",
        "                        if not np.isnan(validation_df.loc[user, movie]):\n",
        "                            rmse += (validation_df.loc[user, movie] - predictions.loc[user, movie]) ** 2\n",
        "                            count += 1\n",
        "\n",
        "                if count > 0:\n",
        "                    rmse = np.sqrt(rmse / count)\n",
        "\n",
        "                if rmse < best_rmse:\n",
        "                    best_rmse = rmse\n",
        "                    best_params = {'K': K, 'steps': steps, 'alpha': alpha, 'beta': beta}\n",
        "\n",
        "print(\"Melhores parâmetros:\", best_params)\n",
        "print(\"Melhor RMSE:\", best_rmse)\n"
      ],
      "metadata": {
        "id": "X8mvr0uCWLXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Avaliação no conjunto de teste\n",
        "### Aqui, usamos os melhores parâmetros encontrados para ajustar o modelo final e calcular o erro no conjunto de teste."
      ],
      "metadata": {
        "id": "TOP77_sKWLaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo com os melhores parâmetros no conjunto de treinamento completo\n",
        "fat_final = MatrixFactorization(dataframe=df, K=best_params['K'], steps=best_params['steps'],\n",
        "                                alpha=best_params['alpha'], beta=best_params['beta'])\n",
        "fat_final.fit()\n",
        "predictions_final = pd.DataFrame(fat_final.predict(), columns=df.columns, index=df.index)"
      ],
      "metadata": {
        "id": "mnWKQEr8WLcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar no conjunto de teste\n",
        "rmse_test = 0\n",
        "count_test = 0\n",
        "for user in test_df.index:\n",
        "    for movie in test_df.columns:\n",
        "        if not np.isnan(test_df.loc[user, movie]):\n",
        "            rmse_test += (test_df.loc[user, movie] - predictions_final.loc[user, movie]) ** 2\n",
        "            count_test += 1\n",
        "\n",
        "if count_test > 0:\n",
        "    rmse_test = np.sqrt(rmse_test / count_test)\n",
        "\n",
        "print(\"RMSE no conjunto de teste:\", rmse_test)\n"
      ],
      "metadata": {
        "id": "EHfNyIZEWLfO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFvoycIHWLha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZInTPIF1WLkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rvoZO3ClWLmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZcMP0u20WLpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfURVPOMWLsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOm30PNQWLu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQgjpBaXWLxM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}